{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohul8hrP-EHS",
        "outputId": "facf23f5-e308-4171-f062-8b5a410baff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000 Loss 0.247665\n",
            "Epoch 2000 Loss 0.230247\n",
            "Epoch 3000 Loss 0.182979\n",
            "Epoch 4000 Loss 0.141268\n",
            "Epoch 5000 Loss 0.083919\n",
            "Epoch 6000 Loss 0.040562\n",
            "Epoch 7000 Loss 0.021949\n",
            "Epoch 8000 Loss 0.013791\n",
            "Epoch 9000 Loss 0.009632\n",
            "Epoch 10000 Loss 0.007227\n",
            "[(array([0, 0]), 0.1), (array([0, 1]), 0.93), (array([1, 0]), 0.93), (array([1, 1]), 0.09)]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "#Define the sigmoid functions and its derivatives\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  return (x) * (1 -(x))\n",
        "\n",
        "#Define mean squared error loss functions\n",
        "def mse(y_true, y_pred):\n",
        "  return np.mean((y_true - y_pred)**2)\n",
        "\n",
        "#Define the input and expected outputs for XOR\n",
        "inputs=np.array(([0,0],[0,1],[1,0],[1,1]))\n",
        "outputs=np.array(([0],[1],[1],[0]))\n",
        "\n",
        "#Intialize weights and biases randomly\n",
        "np.random.seed(42)\n",
        "input_size=2\n",
        "hidden_size=2\n",
        "output_size=1\n",
        "\n",
        "weights_input_hidden=np.random.rand(input_size,hidden_size)\n",
        "bias_hidden=np.random.rand(hidden_size)\n",
        "weights_hidden_output=np.random.rand(hidden_size,output_size)\n",
        "bias_output=np.random.rand(output_size)\n",
        "\n",
        "#Training Parameter\n",
        "learning_rate=0.1\n",
        "epochs=10000\n",
        "\n",
        "#training loop\n",
        "for epoch in range(epochs):\n",
        "  hidden_input=np.dot(inputs,weights_input_hidden)+bias_hidden #a1\n",
        "  hidden_output=sigmoid(hidden_input) #h1\n",
        "  final_input=np.dot(hidden_output,weights_hidden_output)+bias_output #a2\n",
        "  final_output=sigmoid(final_input) #h2\n",
        "\n",
        "#compute the loss\n",
        "  loss=mse(outputs,final_output)\n",
        "\n",
        "#Backpropogation\n",
        "  error_output=final_output-outputs\n",
        "  gradient_output=error_output*sigmoid_derivative(final_output)\n",
        "\n",
        "#hidden layer error and gradient\n",
        "  error_hidden=np.dot(gradient_output, weights_hidden_output.T)\n",
        "  gradient_hidden=error_hidden*sigmoid_derivative(hidden_output)\n",
        "\n",
        "#update weights and biases\n",
        "  weights_hidden_output-=learning_rate*np.dot(hidden_output.T,gradient_output)\n",
        "  bias_output-=learning_rate*np.mean(gradient_output,axis=0)\n",
        "  weights_input_hidden-=learning_rate*np.dot(inputs.T,gradient_hidden)\n",
        "  bias_hidden-=learning_rate*np.mean(gradient_hidden,axis=0)\n",
        "\n",
        "#Print loss every 1000 epochs\n",
        "  if(epoch+1)%1000==0:\n",
        "    print(f\"Epoch {epoch+1} Loss {loss:6f}\")\n",
        "\n",
        "#compute the output for each input pair after training\n",
        "results=[]\n",
        "for input_pair in inputs:\n",
        "    hidden_input=np.dot(input_pair,weights_input_hidden)+bias_hidden\n",
        "    hidden_output=sigmoid(hidden_input)\n",
        "    final_input=np.dot(hidden_output,weights_hidden_output)+bias_output\n",
        "    final_output=sigmoid(final_input)\n",
        "    results.append((input_pair,np.round(final_output[0],2)))\n",
        "\n",
        "print(results)"
      ]
    }
  ]
}